{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from cv2 import imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT VIDEO DIRECTORY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = r''\n",
    "\n",
    "# Retrieve a list of the videos stored in the directory above\n",
    "video_files = glob(os.path.join(video_directory, '*.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Initialize a counter for suitable videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suitable_videos = 0\n",
    "\n",
    "flicker_frames_list = [] \n",
    "total_frames_list = [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Iterate over each video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: D:\\ΠΡΑΓΜΑΤΑ ΠΟΥ ΚΡΑΤΩ\\masters\\sxolj\\videos\\Kakashi Vs Obito _ Naruto Shippuden.mp4\n",
      "Number of frames: 5377\n",
      "FPS: 30.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for video_file in video_files:\n",
    "   \n",
    "    print(f\"Processing video: {video_file}\")\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # total frame s of each video (number)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) # get the FPS\n",
    "    total_frames_list.append(n_frames) # Store the total number of frames in the list \n",
    "\n",
    "\n",
    "    print(f\"Number of frames: {n_frames}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "\n",
    "    # Initialize variables for analysis\n",
    "    luminance_threshold = 130  # fixed threshold we defined through references studying\n",
    "    flicker_threshold = 1  # Set flickering frames threshold to consider a video safe\n",
    "    flicker_frames = [] # list used to store the flickering frames\n",
    "\n",
    "\n",
    "    # Perform the desired actions on each frame\n",
    "    ret, prev_img = cap.read()  # Read the first frame\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the previous and the current frame to grayscale\n",
    "        gray_prev = cv2.cvtColor(prev_img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_current = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        # Calculate the absolute difference between the grayscale representations of the previous and current frames\n",
    "        diff = cv2.absdiff(gray_prev,gray_current)\n",
    "\n",
    "        # Calculate the average difference of the frame to measure the overall change in luminance\n",
    "        average_difference = np.mean(diff)\n",
    "\n",
    "        # Check if the average difference exceeds the luminance threshold, which indicates potential flickering\n",
    "        if average_difference > luminance_threshold:\n",
    "            flicker_frames.append(frame_count)\n",
    "            if frame_count < n_frames:   # Check if the frame count is within the valid range \n",
    "                height = 350/max(prev_img.shape[0], img.shape[0])\n",
    "                frame1 = cv2.resize(prev_img, (int(prev_img.shape[1] * height),int(prev_img.shape[0]*height)))# resize the frames to have the same height while maintaining the aspect ratio\n",
    "                frame2 = cv2.resize(img, (int(img.shape[1]  * height),int(img.shape[0]*height)))\n",
    "\n",
    "                # Combine the resized frames horizontally in order to perform a side by side comparison\n",
    "                combined_frames = np.concatenate((frame1, frame2), axis=1)\n",
    "\n",
    "                #Display the combined frames to visually observe the potential flickering\n",
    "                cv2.imshow(\"Frames\", combined_frames)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "        # Update the previous frame to be the current frame, ready for the next iteration\n",
    "        prev_img = img\n",
    "\n",
    "        frame_count += 1 # increase the frame count by 1\n",
    "\n",
    "    # Release the video capture object (this happens to free resources)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # using FFmpeg to convert the video to audio so as to perform the audio analysis\n",
    "    audio_file = video_file.replace('.mp4', '.wav')\n",
    "    subprocess.run(['ffmpeg', '-i', video_file, '-vn', '-acodec', 'pcm_s16le', '-ar', '0', '-ac', '2', audio_file])\n",
    "\n",
    "    # Perform audio analysis \n",
    "    audio, sr = librosa.load(audio_file, sr=None)  # Load audio with original sampling rate\n",
    "\n",
    "    # Calculate the decibel levels of the loaeded audio, the average decibel, and the maximum\n",
    "    decibel_levels = librosa.amplitude_to_db(np.abs(audio))\n",
    "    average_decibel = np.mean(decibel_levels)\n",
    "    max_decibel = np.max(decibel_levels)\n",
    "\n",
    "    # Perform high-frequency analysis\n",
    "    fmax = 300  \n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, fmax=fmax)\n",
    "\n",
    "    # Calculate the presence of high-frequency content in the spectrogram\n",
    "    high_freq_presence = np.sum(spectrogram[20:, :]) / np.sum(spectrogram)\n",
    "\n",
    " #Analysis based on our thresholds to evaluate the suitability\n",
    "\n",
    "    # Perform Photosensitive Epilepsy Analysis\n",
    "    if len(flicker_frames) >= flicker_threshold:\n",
    "        print(\"This video may contain potential epilepsy triggers.\")\n",
    "        print(f\"the frames {flicker_frames} in this video may trigger Epilepsy \")\n",
    "\n",
    "\n",
    "\n",
    "    # Evaluate the suitability of audio for kids\n",
    "    if max_decibel > 90 or average_decibel > 50:   #\n",
    "        print(\"This video may have loud or intense audio that may not be safe for kids.\")\n",
    "    else:\n",
    "        print(f\"This video sound is safe for kids. as the max decibel level is {max_decibel}\")\n",
    "\n",
    "    # Evaluate the presence of high-frequency components\n",
    "    if high_freq_presence > 0.2:\n",
    "        print(f\"This video contains {high_freq_presence} audio percentage.\")\n",
    "    else:\n",
    "        print(f\"This video does not have significant {high_freq_presence}  audio percentage.\")\n",
    "\n",
    "    \n",
    "    os.remove(audio_file)\n",
    "\n",
    "    \n",
    "    if len(flicker_frames) < flicker_threshold and max_decibel <= 90 and average_decibel <= 50 and high_freq_presence <= 0.2:\n",
    "        suitable_videos += 1  # Increment suitable_videos count\n",
    "\n",
    "    flicker_frames_list.append(len(flicker_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the flicker frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(video_files)), flicker_frames_list, tick_label=[os.path.basename(file) for file in video_files])\n",
    "plt.xlabel('File Name')\n",
    "plt.ylabel('Number of Flicker Frames')\n",
    "plt.title('Flicker Frames vs. Total Frames')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "print(\"The Flicker Frames of the videos tested compared to the total frames of the videos are shown below\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the percentage_suitable to be the quotient  of the amount of suitable_videos divided by thu number of all videos multiplied by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentage_suitable = (suitable_videos / len(video_files)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the degree of appropriateness based on the percentage of suitable videos (fixed by us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if percentage_suitable == 100:\n",
    "    degree_of_appropriateness = \"Suitable for all children\"\n",
    "elif 80 <= percentage_suitable < 100:\n",
    "    degree_of_appropriateness = \"Suitable for children over 6 years old\"\n",
    "elif 60 <= percentage_suitable < 80:\n",
    "    degree_of_appropriateness = \"Suitable for children over 10 years old\"\n",
    "elif 40 <= percentage_suitable < 60:\n",
    "    degree_of_appropriateness = \"Suitable for children over 12 years old\"\n",
    "elif 20 <= percentage_suitable < 40:\n",
    "    degree_of_appropriateness = \"Suitable for children over 15 years old\"\n",
    "else:\n",
    "    degree_of_appropriateness = \"Not suitable for children\"\n",
    "\n",
    "\n",
    "print(f\"Therefore the Series Degree of Appropriateness is :  {percentage_suitable} % and {degree_of_appropriateness}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
